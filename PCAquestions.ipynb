{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA questions\n",
    "\n",
    "The followings consider a data matrix $X$ with $n$ rows of samples and $p$ columns of attributes.\n",
    "\n",
    "###### What is the relationship between the eigenvalues of $X^TX$ and the variance of the data?\n",
    "\n",
    "*A: The eigvenvalues are the variances in the corresponding directions of principal components.*\n",
    "\n",
    "###### What is the meaning of the first (or the second) Principal Component (PC)?\n",
    "\n",
    "*A: The first PC is the direction with the highest variance. The second follows.*\n",
    "\n",
    "###### How many PCs does the data have?\n",
    "\n",
    "*A: For data points in a $p$ dimensional space, the total number of PCs is $p$.*\n",
    "\n",
    "###### What's the indication of a zero eigenvalue of $X^TX$?\n",
    "\n",
    "*A: This means that while the data lives in a subspace of the $p$-dimensional space, i.e., the data can be compressed without loss of information.*\n",
    "\n",
    "###### In what cases will the matrix $X^TX$ have zero eigenvalues?\n",
    "\n",
    "*A: This happens when the columns in the data matrix $X$ are linearly dependent, or when the number of samples ($n$) is smaller than the dimensionality ($p$).*\n",
    "\n",
    "###### What are the applications and limitations of PCA?\n",
    "\n",
    "*A: Applications include dimension reduction (e.g., for visualization purpose) and data denoising before learning a predictive model (e.g., linear models).*\n",
    "\n",
    "# Linear regression and ANOVA\n",
    "\n",
    "The followings consider an input matrix $X$ with $n$ rows of samples and $p$ columns of attributes, and a corresponding response vector $y$ with $n$ rows.\n",
    "\n",
    "###### How does a linear regression model look like?\n",
    "*A: The general form is $y = \\sum_{i=1}^p a_i f_i(x)+\\varepsilon$, where $a_i$ are unknown model parameters, $f_i(x)$ are pre-defined functions of $x$ and $\\varepsilon$ is the random error. Note that $f_i(x)$ can be nonlinear functions. So the linear model is only required to be linear with respect to the model parameters* \n",
    "\n",
    "###### What are the assumptions involved in a linear model?\n",
    "*A: The random errors $\\varepsilon$ from all samples are independently and identically distributed. In addition, the errors all follow a normal distribution: $\\varepsilon \\sim N(0,\\sigma^2)$.*\n",
    "\n",
    "###### Derivation of an Ordinary Least Square estimator.\n",
    "*A: See notes*\n",
    "\n",
    "###### What is the mean of this estimator and what is the variance?\n",
    "*A: $E(\\beta ^ *) = \\beta$, $Var(\\beta ^ *) = (X^TX)^{-1}\\sigma^2$.*\n",
    "\n",
    "###### In what cases, we cannot get a unique OLS estimator?\n",
    "*A: When $X^TX$ is not invertable.*\n",
    "\n",
    "###### In what cases, we get a unique OLS estimator?\n",
    "*A: When $X^TX$ is invertable...*\n",
    "\n",
    "###### With all potential linear models (e.g., with polynomial terms), how do you determine which model to use?\n",
    "*A: The key idea is to balance training error (the unexplained variance of the data) and the model complexity (the number of model parameters). There are three ways: AIC, BIC and cross validation. We pick the model with the lowest value from either of these three.*\n",
    "\n",
    "###### When using ANOVA for linear models, what is the definition of the F statistic?\n",
    "*A: F statistic is the ratio between explained and unexplained variances. The larger the value is, the smaller the gap between the data and the model.*\n",
    "\n",
    "###### What conclusions can you make when the F statistic is large (or its p-value is small)?\n",
    "*A: See above.*\n",
    "\n",
    "###### What assumptions does ANOVA rely on when testing a linear model?\n",
    "*A: All random errors are i.i.d.*\n",
    "\n",
    "###### When testing the mean of two samples, what is the relationship between ANOVA and a t-test?\n",
    "*A: These two lead to the same conclusion when the two sample sets are assumed to have the same variance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
