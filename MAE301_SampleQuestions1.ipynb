{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE 301 Sample Questions 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Binary random variables\n",
    "\n",
    "Two binary random variables A and B have probabilities $P(A=1) = 0.5$, $P(B=1) = 0.8$ and $P(A=1,B=1) = 0.4$. \n",
    "\n",
    "* (a) Are they mutually exclusive?\n",
    "* (b) Are they independent?\n",
    "* (c) What is the conditional probability P(A=1|B=0)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "* (a) Since $P(A=1,B=1) \\neq 0$, they are not mutually exclusive.\n",
    "* (b) Since $P(A=1,B=1) = P(A=1)P(B=1)$, they are independent.\n",
    "* (c) $$P(A=1|B=0) = \\frac{P(A=1,B=0)}{P(B=0)} = \\frac{(0.5-0.4)}{1-0.8} = 0.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Bayes' Theorem\n",
    "\n",
    "Consider two random variables: $A=1$ represents ASU winning the game, $B=1$ represents the temperature being over 90 degrees. Assume that $P(A=1|B=1) = 0.9$, $P(A=1|B=0) = 0.4$ (I'm just making up a number), and $P(B=1) = 0.8$. What is the chance for the temperature to be lower than 90 degrees when ASU wins the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "We will calculate $P(B=0|A=1)$. From Bayes' Theorem, we have\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "P(B=0|A=1) &= \\frac{P(A=1|B=0)P(B=0)}{P(A=1)} = \\frac{P(A=1|B=0)P(B=0)}\n",
    "{P(A=1|B=0)P(B=0)+P(A=1|B=1)P(B=1)} \\\\\n",
    "&= \\frac{0.4*(1-0.8)}{0.4*(1-0.8)+0.9*0.8}= 0.1\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Normal distribution\n",
    "\n",
    "Assume that $X$ is a random variable with probability density function\n",
    "$$ f(x) = \\frac{1}{\\sqrt{8\\pi}}e^{-\\frac{(x-20)^2}{8}} $$\n",
    "Determine the following probabilities\n",
    "* (a) $P(X>18)$\n",
    "* (b) $P(16<~ X<18)$\n",
    "\n",
    "Find the $x$ values such that\n",
    "* (c) $P(x <~ X<20)=0.2$\n",
    "* (d) $P(X <~ x)=0.4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "Comparing with the general form of normal distribution to get $\\mu = 20$, $\\sigma = 2$. In the following, $\\Phi(x)$ is the cdf of a normal distribution.\n",
    "\n",
    "* (a) $P(X>18) = P\\left(\\frac{X-\\mu}{\\sigma} > \\frac{18-20}{2}\\right) = P(Z>-1) = P(Z<1) = \\Phi(1) = 0.8413$\n",
    "* (b) $P(16 <~ X<18) = P\\left(\\frac{16-20}{2}<\\frac{X-\\mu}{\\sigma}<\\frac{18-20}{2}\\right) = P(-2<~Z<-1) = P(1<~Z<2) = \\Phi(2)-\\Phi(1) = 0.1359$\n",
    "* (c) $$0.2=P(x <~ X<20) = P\\left(\\frac{x-20}{2}<\\frac{X-\\mu}{\\sigma}<\\frac{20-20}{2}\\right)<P(\\frac{x-20}{2} <~ Z<0)$$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "&\\Rightarrow 0.2 = P(Z<0)-P(Z-\\frac{x-20}{2}) = 0.5-P(Z<\\frac{x-20}{2})\\\\\n",
    "&\\Rightarrow P(Z<\\frac{x-20}{2})=0.3\\\\\n",
    "&\\Rightarrow \\Phi(\\frac{x-20}{2})=0.3\\\\\n",
    "&\\Rightarrow \\frac{20-x}{2} = -0.525 \\Rightarrow x=18.95\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Normal distribution\n",
    "\n",
    "Let $X$ be a normal random variable with mean $\\mu$ and standard deviation $\\sigma$, $Z$ be a standard normal random variable. Prove that\n",
    "$$ P(X <~ x) = P(Z < \\frac{x-\\mu}{\\sigma}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "The cdf of $X$ is: \n",
    "$$ P(X <~ x) = \\int_{-\\infty}^{x} \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x'-\\mu)^2}{2\\sigma^2}}dx'$$\n",
    "\n",
    "Let $z' = \\frac{x'-\\mu}{\\sigma}$, or $x' = \\sigma z' + \\mu$. Plug this into the cdf to have\n",
    "$$ P(X <~ x) = \\int_{-\\infty}^{x} \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(z')^2}{2}}d(\\sigma z'+\\mu) = \\int_{-\\infty}^{\\frac{x-\\mu}{\\sigma}} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{(z')^2}{2}}dz'=P(Z < \\frac{x-\\mu}{\\sigma})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Expectation (mean) and variance\n",
    "\n",
    "For a random variable $X$, show that $Var(X) = E(X^2)-E(X)^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "By definition, $Var(X) = E((X-E(X))^2) = E(X^2-2XE(X)+E(X)^2)$. Let $E(X)= \\mu$. We have\n",
    "$$E(X^2-2XE(X)) = \\int_X (x^2-2x\\mu)p(x)dx = \\int_X x^2p(x)dx - 2\\mu\\int_X xp(x)dx = E(X^2) - 2\\mu^2$$\n",
    "So $Var(X) = E(X^2) - 2\\mu^2 + \\mu^2 = E(X^2) - \\mu^2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Independent random variables\n",
    "\n",
    "Let $X$ and $Y$ be independent random variables, with means $\\mu_1$ and $\\mu_2$, and variances $\\sigma_1^2$ and $\\sigma_2^2$, respectively. Calculate $E(X-Y)$ and $Var(X-Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "Without loss of generality, we prove for continuous $X$ and $Y$. By definition,\n",
    "$$E(X-Y) = \\int_X \\int_Y (x-y)P(X-Y=x-y)dxdy = \\int_X \\int_Y (x-y)P(X=x|Y=y)P(Y=y)dxdy $$\n",
    "Since $X$ and $Y$ are independent, we have $P(X=x|Y=y) = P(X=x)$, therefore\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "E(X-Y) & = \\int_X \\int_Y (x-y)P(X=x)P(Y=y)dxdy\\\\\n",
    "& = \\int_X \\int_Y \\left(xP(X=x)P(Y=y)-yP(X=x)P(Y=y)\\right) dxdy\\\\\n",
    "& = \\int_X \\int_Y xP(X=x)P(Y=y) dxdy - \\int_X \\int_Y yP(X=x)P(Y=y) dxdy\\\\\n",
    "& = \\int_X xP(X=x)\\left(\\int_Y P(Y=y)dy\\right)dx - \\int_Y yP(Y=y)\\left(\\int_X P(X=x)dx\\right)dy\\\\\n",
    "& = \\int_X xP(X=x)dx - \\int_Y yP(Y=y)dy= E(X)-E(Y) = \\mu_1-\\mu_2\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "For variance, we have\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "Var(X-Y) & = E((X-Y)^2)-E(X-Y)^2 = \\int_X \\int_Y (x-y)^2 P(X-Y=x-y)dxdy - (\\mu_1-\\mu_2)^2\\\\\n",
    "&= \\int_X \\int_Y (x^2+y^2-2xy) P(X=x)P(Y=y) dxdy - (\\mu_1-\\mu_2)^2\\\\\n",
    "&= \\int_X x^2 P(X=x) dx + \\int_Y y^2 P(Y=y)dy - 2\\int_X \\int_Y xyP(X=x)P(Y=y)dxdy - (\\mu_1-\\mu_2)^2\\\\\n",
    "&=E(X^2)+ E(Y^2) - 2\\int_X x \\left(\\int_Y y P(Y=y)dy \\right)P(X=x)dx- (\\mu_1-\\mu_2)^2\\\\\n",
    "&=E(X^2)+ E(Y^2) - 2\\int_X x \\mu_2 P(X=x)dx- (\\mu_1-\\mu_2)^2\\\\\n",
    "&=E(X^2)+ E(Y^2) - 2\\mu_1\\mu_2- (\\mu_1-\\mu_2)^2\\\\\n",
    "&=E(X^2) - E(X)^2 + E(Y^2) - E(Y)^2\\\\\n",
    "&=Var(X)+Var(Y)\n",
    "\\end{aligned}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7: Sample mean and sample variance\n",
    "\n",
    "Let $X_1$, $X_2$,..., $X_n$ be iid, with mean $\\mu$ and variance $\\sigma^2$, and $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$. Show that $E(\\bar{X}) = \\mu$ and $Var(\\bar{X}) = \\frac{\\sigma^2}{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "See notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8: Binomial distribution\n",
    "\n",
    "Consider a coin that we assume to be fair, i.e., $P(\\text{Head}) = 0.5$. Let's say you did an experiment by flipping the coin 1000 times, among which 600 times are head. Do you still believe it is a fair coin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "We know that the number of head (or tail) follows a binomial distribution with mean $0.5*1000=500$ and variance $0.5*(1-0.5)*1000 = 250$. We also know that when the sample size is large, the binomial distribution converges to a normal distribution (there is a proof on blackboard under readings). Alternatively, we can consider each flip as a sample and the percentage of heads as the sample mean. Therefore, following the Central Limit Theorem, the percentage of heads (and thus the total count of heads) follows a normal distribution with large sample size. \n",
    "\n",
    "Let $X$ be the total number of heads, with $\\mu = 500$ and $\\sigma^2 = 250$. Then $Z = (X-\\mu)/\\sigma$ approximately follows standard normal. The probability for $X$ to be larger than 600 is\n",
    "$$ P(X>600) = P(Z>\\frac{600-500}{\\sqrt{250}}) \\approx 0.0. $$\n",
    "This indicates that the chance to observe 600 heads from 1000 flips is unlikely when the coin is fair.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9: $Z$-test\n",
    "\n",
    "Two different box-filling machines are used to fill cereal boxes on the assembly line. The critical\n",
    "measurement influenced by these machines is the weight of the product in the machines. Engineers are\n",
    "quite certain that the variance of the weight of product is $\\sigma^2 = 1$ ounce. Experiments are conducted using both machines with sample sizes of 36 each. The sample averages for machine $A$ and $B$ are $\\bar{x}_A = 4.5$ ounces and $\\bar{x}_B = 4.7$ ounces. Engineers seemed surprised that the two sample averages for the filling machines were so different.\n",
    "\n",
    "* (a) Determine the probability $P(\\bar{X}_B-\\bar{X}_A \\geq 0.2)$ under the condition that $\\mu_A = \\mu_B$\n",
    "* (b) Do the aforementioned experiments seem to, in any way, strongly support a conjecture that the two population means for the two machines are different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "* (a) Given $\\bar{x}_A = 4.5$, $\\sigma_A = 1$, $n_A = 36$, $\\bar{x}_B = 4.7$, $\\sigma_B = 1$, $n_B = 36$\n",
    "\n",
    "Assuming $\\mu_A = \\mu_B$, we have\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "P(\\bar{X}_B-\\bar{X}_A \\geq 0.2) & = P\\left(\\frac{(\\bar{X}_B-\\bar{X}_A)-(\\mu_B-\\mu_A)}{\\sqrt{(\\sigma^2_B/n_B)+(\\sigma_A^2/n_A)}} \\geq \\frac{0.2-0}{\\sqrt{(1/36)+(1/36)}}\\right)\\\\\n",
    "&=P(Z\\geq 0.85) = 1-\\Phi(0.85) = 1-0.8023 = 0.1977\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "* (b) Assume the population means are equal, i.e., $\\mu_A = \\mu_B$. With known variances, we use $z$-test\n",
    "$$z=\\frac{(\\bar{x}_B-\\bar{x}_A)-(\\mu_B-\\mu_A)}{\\sqrt{(\\sigma^2_B/n_B)+(\\sigma_A^2/n_A)}} = \\frac{(4.7-4.5)-0}{\\sqrt{(1/36)+(1/36)}} = 0.85$$\n",
    "\n",
    "Two-tailed test with significance level $\\alpha=5\\%$ lead to $z \\in [-1.96,1.96]$ if $\\mu_B = \\mu_A$ is true. Since the $z$ value is 0.85, the assumption $\\mu_B = \\mu_A$ cannot be rejected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10: Statistical tests\n",
    "\n",
    "Let $\\bar{X}_A$ and $\\bar{X}_B$ be the sample means of two random variables $X_A$ and $X_B$, with sample variances $S_A^2$ and $S_B^2$, respectively. List usage of $Z$-test, $T$-test, $T'$-test, $\\chi^2$-test, and $F$-test, and their underlying assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "One-sample $Z$-test: Test if the hypothesis $\\mu_A = \\mu$ is true, where $\\mu$ is some predefined value. The alternative hypothesis is $\\mu_A \\neq \\mu$ for a two-sided (tailed) test, or $\\mu_A < \\mu$ ($\\mu_A>\\mu$) for a one-sided test. Use this test when (1) the true variances $\\sigma_A$ is known, and (2) either sample size is large ($n_A>30$) or $X_A$ is normally distributed.\n",
    "\n",
    "Two-sample $Z$-test: Test if the hypothesis $\\mu_A = \\mu_B$ is true. The alternative hypothesis is $\\mu_A \\neq \\mu_B$ for a two-sided (tailed) test, or $\\mu_A < \\mu_B$ ($\\mu_A>\\mu_B$) for a one-sided test. Use this test when (1) the true variances $\\sigma_A$ and $\\sigma_B$ are known, and (2) either sample sizes are large ($n_A$, $n_B>30$) or both $X_A$ and $X_B$ are normally distributed.\n",
    "\n",
    "One-sample and two-sample $T$-test: Same purpose as $Z$-test. Use when (1) the true variances $\\sigma_A$ and $\\sigma_B$ are equal and can only be approximated by the sample variances. Requires $X_A$ and $X_B$ to be normal. Does not require large sample size. \n",
    " \n",
    "Two-sample $T'$-test: Same as $T$-test. But does not assume $\\sigma_A = \\sigma_B$.\n",
    " \n",
    " $\\chi^2$-test: Test if the hypothesis $\\sigma^2_A = \\sigma^2$ is true, where $\\sigma^2$ is some predefined value. The alternative hypothesis is $\\sigma^2_A \\neq \\sigma^2$ for a two-sided (tailed) test, or $\\sigma^2_A < \\sigma^2$ ($\\sigma^2_A > \\sigma^2$) for a one-sided test. Requires $X_A$ and $X_B$ to be normal. Does not require large sample size.\n",
    " \n",
    " $F$-test: Test if the hypothesis $\\sigma^2_A = \\sigma^2_B$ is true. The alternative hypothesis is $\\sigma^2_A \\neq \\sigma^2_B$ for a two-sided (tailed) test, or $\\sigma^2_A < \\sigma^2_B$ ($\\sigma^2_A > \\sigma^2_B$) for a one-sided test. Requires $X_A$ and $X_B$ to be normal. Does not require large sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 11: Penney's game (from Quora)\n",
    "\n",
    "* (a) Flip two fair coins in a sequence. How many trials will it take on average to get two Heads (HH)? What about first Head then Tail (HT)?\n",
    "\n",
    "* (b) Let's play a game: we flip a coin repeatedly until either HH emerges (I win) or HT emerges (you win). Is the game fair?\n",
    "\n",
    "* (c) We play the let's-flip-a-coin-until-a-pattern-emerges game. You pick HHT as your pattern, I pick THH. We flip a fair coin repeatedly until we get HHT in a row (you win) or THH in a row (I win). Is the game fair?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "Note: This problem is tricky. This level of problems won't appear in the exam. \n",
    "* (a) Consider $x_1$ the expected number of flips needed for HH after a Tail (or haven't flipped), and $x_2$ the expected number of flips needed for HH after a Head. The relationship between the two is as follows:\n",
    "$$ x_2 = 0.5*1 + 0.5*(1+x_1) $$\n",
    "$$ x_1 = 0.5*(1+x_2) + 0.5*(1+x_1)$$\n",
    "Solving these two to get $x_1=6$ and $x_2=4$. So the expected number of flips needed for HH from the beginning is 6. \n",
    "For HT, we can similarly define $x_1$ as the expected number of flips needed after a Tail (or haven't flipped), and $x_2$ that after a Head. Then\n",
    "$$ x_2 = 0.5*1 + 0.5*(x_2+1) $$\n",
    "$$ x_1 = 0.5*(x_2+1) + 0.5*(x_1+1) $$\n",
    "This leads to $x_1 = 4$ and $x_2 = 2$. So the expected number of flips needed for HH from the beginning is 4. HT requires less flips than HH on average:)\n",
    "\n",
    "* (b) It is a fair game. Once we hit H, there is equal chance to have H or F in the next flip. The difference from (a) is that here the game ends either we have HH or HF, while in (a) the game continues (refreshes) when we hit HF (when the target is HH) or HH (when the target is HF).\n",
    "\n",
    "* (c) Define the following states: 1: start, 2: H, 3: HH, 4: HHT, 5: T, 6: TH, 7: THH. Let $p_i$ be the probability of reaching HHT at state $i$: $p_i = P(HHT|i)$. We have\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "p_4 & = 1,\\\\\n",
    "p_3 & = P(HHT|HH) = P(HHT|HHT)P(T) + P(HHT|HHH)P(H) = 0.5 + 0.5*p_3\\\\\n",
    "p_2 & = P(HHT|H) = P(HHT|HH)P(H) + P(HHT|HT)P(T) = 0.5 + 0.5*p_5\\\\\n",
    "p_1 & = P(HHT) = P(HHT|H)P(H) + P(HHT|T)P(T) = 0.5*p_2 + 0.5*p_5\\\\\n",
    "p_5 & = P(HHT|T) = P(HHT|TT)P(T) + P(HHT|TH)P(H) = 0.5*p_5 + 0.5*p_6\\\\\n",
    "p_6 & = P(HHT|TH) = P(HHT|THH)P(H) + P(HHT|THT)P(T) = 0.5*p_7 + 0.5*p_5\\\\\n",
    "p_7 & = P(HHT|TTH) = 0\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "This leads to\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& p_3 = p_4 = 1, p_7 = 0\\\\\n",
    "& p_6 = 0.5*p_5, p_5 = 0.5*p_6+0.5*p_5 \\rightarrow p_5=p_6 = 0\\\\\n",
    "& p_2 = 0.5 + 0.5*p_5 = 0.5\\\\\n",
    "& p_1 = 0.5*0.5 = 0.25\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Therefore, the chance to get HHT is 0.25, and the chance to get THH is 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12: Another tricky question from Quora\n",
    "\n",
    "* (a) Pick a random family uniformly among all families with exactly 2 children of which one (at least) is a girl. What is the likelihood that the chosen family has 2 girls?\n",
    "\n",
    "* (b) What if we pick a random family among all families with exactly 2 children, at least one of which is a girl born on a Tuesday? Ignore twins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "* (a) Let $X$ be a binary random variable: $X = 1$ for boy and $X=0$ for girl. It is fair to assume $P(X = 1) = P(X=0) = 0.5$. The chance of having two girls conditioned on one is girl is\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "P(X_1=0,X_2=0| X_1=0 ~OR~ X_2=0) & = \\frac{P(X_1=0,X_2=0)}{P(X_1=0 ~OR~ X_2=0)}\\\\\n",
    "& = \\frac{P(X_1=0,X_2=0)}{(P(X_1=0,X_2=0)+P(X_1=0,X_2=1)+P(X_1=1,X_2=0))}\\\\\n",
    "& = 1/3.\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "* (b) Let $Y$ be the DOB, taking seven states with even chances. The chance of having two girls conditioned on one is girl born on Tuesday is\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "P(X_1=0,X_2=0 | (X_1 = 0, Y_1 = 2)~ OR~ (X_2=0, Y_2=2)) &= \\frac{P(X_1=0,X_2=0,Y_1=2 ~OR~ Y_2=2)}{P((X_1 = 0, Y_1 = 2) ~OR~ (X_2=0, Y_2=2))}\\\\\n",
    "&= \\frac{1/4*(1-(6/7)^2)}{(2*7*2-1)/(2*7*2*7)}\\\\\n",
    "&= 0.482 \n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}